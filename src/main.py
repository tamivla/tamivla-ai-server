# src/main.py
import sys
import os
sys.stdout.reconfigure(encoding='utf-8')

import path_fix

from pathlib import Path
from fastapi import FastAPI
from contextlib import asynccontextmanager
import uvicorn
from loguru import logger

# –¢–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å–µ—Ä–≤–∏—Å—ã
from services.model_manager import model_manager
from services.model_discovery import model_discovery
from services.embedding_service import embedding_service

# –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã
from api.routes.embeddings import router as embeddings_router
from api.routes.chat import router as chat_router
from api.routes.models import router as models_router

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
BASE_DIR = Path(__file__).parent.parent
MODELS_CACHE = BASE_DIR / "storage" / "models"
LOGS_DIR = BASE_DIR / "storage" / "logs"

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
LOGS_DIR.mkdir(parents=True, exist_ok=True)
MODELS_CACHE.mkdir(parents=True, exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger.remove()
logger.add(
    LOGS_DIR / "server.log",
    rotation="10 MB",
    retention=5,
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    level="INFO"
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Tamivla AI Server (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π) –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    logger.info(f"üìÅ –ú–æ–¥–µ–ª–∏: {MODELS_CACHE}")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
    os.environ['HF_HOME'] = str(MODELS_CACHE)
    os.environ['TRANSFORMERS_CACHE'] = str(MODELS_CACHE)
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    discovery_result = model_discovery.scan_models_cache()
    logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –≤ –∫–µ—à–µ: {discovery_result.get('total_models', 0)}")
    
    # –ü–†–ï–î–ó–ê–ì–†–£–ó–ö–ê –û–°–ù–û–í–ù–û–ô –≠–ú–ë–ï–î–ò–ù–ì–û–í–û–ô –ú–û–î–ï–õ–ò
    try:
        embedding_model_name = "models--intfloat--multilingual-e5-large-instruct"
        logger.info(f"üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {embedding_model_name}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ö–∞–Ω–∏–∑–º –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ model_manager
        success = model_manager.load_model(embedding_model_name, "embedding")
        if success:
            logger.info("‚úÖ –≠–º–±–µ–¥–∏–Ω–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ")
        else:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–æ–≤—É—é –º–æ–¥–µ–ª—å")
            logger.info("‚ÑπÔ∏è –°–µ—Ä–≤–µ—Ä –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É, –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ")
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
        logger.info("‚ÑπÔ∏è –°–µ—Ä–≤–µ—Ä –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É, –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ")
    
    yield
    
    # Shutdown
    logger.info("üõë Tamivla AI Server –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...")
    for model_name in list(model_manager.loaded_models.keys()):
        model_manager.unload_model(model_name)

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
app = FastAPI(
    title="Tamivla AI Server",
    description="OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API —Å–µ—Ä–≤–µ—Ä –¥–ª—è AI –º–æ–¥–µ–ª–µ–π",
    version="1.0.0",
    lifespan=lifespan
)

# OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ä–æ—É—Ç–µ—Ä—ã
app.include_router(embeddings_router, prefix="/v1")
app.include_router(chat_router, prefix="/v1/chat")
app.include_router(models_router, prefix="/v1")

# –ö–ê–°–¢–û–ú–ù–´–ï —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ (–ë–ï–ó –ø—Ä–µ—Ñ–∏–∫—Å–∞ /v1)
app.include_router(models_router)

# –ë–∞–∑–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
@app.get("/")
async def root():
    return {
        "message": "Tamivla AI Server —Ä–∞–±–æ—Ç–∞–µ—Ç!",
        "version": "1.0.0",
        "openai_endpoints": {
            "embeddings": "/v1/embeddings",
            "chat": "/v1/chat/completions", 
            "models": "/v1/models",
            "docs": "/docs"
        },
        "custom_endpoints": {
            "load_model": "/models/load",
            "unload_model": "/models/unload", 
            "loaded_models": "/models/loaded"
        }
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "Tamivla AI Server"}

def start_server():
    try:
        logger.info("–ó–∞–ø—É—Å–∫ Tamivla AI Server...")
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8000,
            log_config=None
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")
        sys.exit(1)

# –í—Ä–µ–º–µ–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
@app.get("/debug/routes")
async def debug_routes():
    routes = []
    for route in app.routes:
        routes.append({
            "path": getattr(route, "path", None),
            "name": getattr(route, "name", None),
            "methods": getattr(route, "methods", None)
        })
    return {"routes": routes}

if __name__ == "__main__":
    start_server()
# src/main.py
import sys
import os
sys.stdout.reconfigure(encoding='utf-8')

import path_fix

from pathlib import Path
from fastapi import FastAPI
from contextlib import asynccontextmanager
import uvicorn
from loguru import logger

# –¢–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å–µ—Ä–≤–∏—Å—ã
from services.model_manager import model_manager
from services.model_discovery import model_discovery

# –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã
from api.routes.embeddings import router as embeddings_router
from api.routes.chat import router as chat_router
from api.routes.models import router as models_router

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
BASE_DIR = Path(__file__).parent.parent
MODELS_CACHE = BASE_DIR / "storage" / "models"
LOGS_DIR = BASE_DIR / "storage" / "logs"

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
LOGS_DIR.mkdir(parents=True, exist_ok=True)
MODELS_CACHE.mkdir(parents=True, exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger.remove()
logger.add(
    LOGS_DIR / "server.log",
    rotation="10 MB",
    retention=5,
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    level="INFO"
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Tamivla AI Server (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π) –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    logger.info(f"üìÅ –ú–æ–¥–µ–ª–∏: {MODELS_CACHE}")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
    os.environ['HF_HOME'] = str(MODELS_CACHE)
    os.environ['TRANSFORMERS_CACHE'] = str(MODELS_CACHE)
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    discovery_result = model_discovery.scan_models_cache()
    logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –≤ –∫–µ—à–µ: {discovery_result.get('total_models', 0)}")
    
    # üî¥ –ü–†–ï–î–ó–ê–ì–†–£–ó–ö–ê –û–°–ù–û–í–ù–´–• –ú–û–î–ï–õ–ï–ô —á–µ—Ä–µ–∑ model_manager
    logger.info("üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
    model_manager.preload_essential_models()
    
    yield
    
    # Shutdown
    logger.info("üõë Tamivla AI Server –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...")
    for model_name in list(model_manager.loaded_models.keys()):
        model_manager.unload_model(model_name)

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ FastAPI
app = FastAPI(
    title="Tamivla AI Server",
    description="OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API —Å–µ—Ä–≤–µ—Ä –¥–ª—è AI –º–æ–¥–µ–ª–µ–π",
    version="1.0.0",
    lifespan=lifespan
)

# OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ä–æ—É—Ç–µ—Ä—ã
app.include_router(embeddings_router, prefix="/v1")
app.include_router(chat_router, prefix="/v1/chat")
app.include_router(models_router, prefix="/v1")

# –ö–ê–°–¢–û–ú–ù–´–ï —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ (–ë–ï–ó –ø—Ä–µ—Ñ–∏–∫—Å–∞ /v1)
app.include_router(models_router)

# –ë–∞–∑–æ–≤—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
@app.get("/")
async def root():
    return {
        "message": "Tamivla AI Server —Ä–∞–±–æ—Ç–∞–µ—Ç!",
        "version": "1.0.0",
        "openai_endpoints": {
            "embeddings": "/v1/embeddings",
            "chat": "/v1/chat/completions", 
            "models": "/v1/models",
            "docs": "/docs"
        },
        "custom_endpoints": {
            "load_model": "/models/load",
            "unload_model": "/models/unload", 
            "loaded_models": "/models/loaded"
        }
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "Tamivla AI Server"}

def start_server():
    try:
        logger.info("–ó–∞–ø—É—Å–∫ Tamivla AI Server...")
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8000,
            log_config=None
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")
        sys.exit(1)

# –í—Ä–µ–º–µ–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
@app.get("/debug/routes")
async def debug_routes():
    routes = []
    for route in app.routes:
        routes.append({
            "path": getattr(route, "path", None),
            "name": getattr(route, "name", None),
            "methods": getattr(route, "methods", None)
        })
    return {"routes": routes}

if __name__ == "__main__":
    start_server()